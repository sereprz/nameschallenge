{
 "metadata": {
  "name": "",
  "signature": "sha256:18482c984f9a1106b2193456889866b76ecad79adec335f515bda4b02faee431"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Required libraries"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note** you might need to download the Wordnet corpus fron nltk (http://www.nltk.org/data.html). This takes a while"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import random\n",
      "import csv\n",
      "import urllib2\n",
      "import pandas as pd\n",
      "import nltk\n",
      "from nltk.corpus import wordnet as wn\n",
      "from nltk.tokenize import RegexpTokenizer\n",
      "from nltk.util import ngrams\n",
      "tokenizer = RegexpTokenizer(r'\\w+')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Load dataset"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "I am using \n",
      "\n",
      "* CSV_Database_of_First_Names.csv and CSV_Database_of_Last_Names.csv as lookups \n",
      "* chicago_employees.csv and olympicathletes.csv as training sets to build n-grams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*First Name*:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://raw.githubusercontent.com/Avaaz/names_challenge/master/datasets/CSV_Database_of_First_Names.csv'\n",
      "webpage = urllib2.urlopen(url)\n",
      "datareader = csv.reader(webpage)\n",
      "first_name = []\n",
      "\n",
      "for row in datareader:\n",
      "    first_name.append(row[0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Last Name*: \n",
      "\n",
      "This file can't be read the same way as above. It seems like the only way of fixing the issue is recreating the file \n",
      "(http://stackoverflow.com/questions/19482970/python-get-list-from-pandas-dataframe-column-headers) so I got around it using pandas, which works just fine"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "last_name = pd.read_csv('https://raw.githubusercontent.com/Avaaz/names_challenge/master/datasets/CSV_Database_of_Last_Names.csv', header = None)\n",
      "last_name = list(last_name.iloc[:,0])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Chicago employees*:\n",
      "\n",
      "The names in this set are in the format 'Last_name, First_name', I am putting them in a list as 'First_name Last_Name'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://raw.githubusercontent.com/Avaaz/names_challenge/master/datasets/chicago_employees.csv'\n",
      "webpage = urllib2.urlopen(url)\n",
      "datareader = csv.reader(webpage)\n",
      "trainingset = []\n",
      "datareader.next() # skip column headings\n",
      "\n",
      "for row in datareader:\n",
      "    trainingset.append(' '.join(list(reversed(row[0].title().split(',  ')))))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*Olympic athlets*:\n",
      "\n",
      "This should include 3-grams from foreign names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "url = 'https://raw.githubusercontent.com/Avaaz/names_challenge/master/datasets/olympicathletes.csv'\n",
      "webpage = urllib2.urlopen(url)\n",
      "datareader = csv.reader(webpage)\n",
      "datareader.next() # skip column headings\n",
      "\n",
      "for row in datareader:\n",
      "    name = row[0].decode('utf-8','ignore').encode()\n",
      "    if name not in trainingset:\n",
      "        trainingset.append(name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Training set/ test set"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "In order to create a test set I randomise the order of the names in the training set and move the top 5% in a different variable testset"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "random.shuffle(trainingset)\n",
      "testset = trainingset[:int(len(trainingset)*0.05)]\n",
      "trainingset = trainingset[int(len(trainingset)*0.05) + 1:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "3-Grams"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "n-grams are sequences of n items from given sequence of text. I'm creating a collection of 3 letter sequences from names in the training set so that is a new 3-gram doesn't appear in the trainin set it's assumed to be gibberish"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "threegrams_names = []\n",
      "\n",
      "for name in trainingset:\n",
      "    for ngram in ngrams(name, 3):\n",
      "        threegrams_names.append(ngram)\n",
      "\n",
      "fdist = nltk.FreqDist(threegrams_names)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Function"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def is_real_name(full_name):\n",
      "    \"\"\"\n",
      "    Given `full_name` as a string, returns the best guest as to whether it is real\n",
      "\n",
      "    Consider the follow names fake:\n",
      "    1. empty\n",
      "    2. 3-grams can't be created\n",
      "    3. > 1/4 of 3-grams are gibberish\n",
      "    4. contains non proper noun words\n",
      "\n",
      "    Otherwise consider the name real\n",
      "    \"\"\"\n",
      "\n",
      "    # split the full name into tokens\n",
      "    tokens = tokenizer.tokenize(full_name)\n",
      "\n",
      "    # 1. consider empty names fake\n",
      "    if not tokens:\n",
      "        return False\n",
      "\n",
      "    # 2. if 3-grams can't be created consider fake\n",
      "    # ngrams is a generator so if list(ngrams(full_name, 3)) = [] the name has less than 3 letters\n",
      "    if not list(ngrams(full_name, 3)):\n",
      "        return False\n",
      "\n",
      "    # 3. reject gibberish\n",
      "    # calculate a gibberish score >= 0\n",
      "    # for every ngram not in the training set, add 1\n",
      "    # if more than a quarter of ngrams are gibberish, consider fake\n",
      "    gibberish_score = 0\n",
      "\n",
      "    # generate 3-grams from full_name. for each 3-gram\n",
      "    for gram in ngrams(full_name,3):\n",
      "        # chek if it appears in the training set\n",
      "        if gram not in fdist.keys():\n",
      "            # increment the gibberish score by one\n",
      "            gibberish_score += 1\n",
      "\n",
      "    if gibberish_score/len(list(ngrams(full_name,3))) > 0.25:\n",
      "        return False\n",
      "\n",
      "    # 4.\n",
      "    # check if it's a sentence/a series of words that are not names, e.g. 'Some Name'\n",
      "    for token in tokens:\n",
      "        # ignore len(token) <= 2: single letters are actually allowed in names, as well as 2-letters words (e.g. JR)\n",
      "        if len(token) > 2:\n",
      "            # wn (wordnet) is a semantic dictionary for the english language, if a word appears in it,\n",
      "            if wn.lemmas(token):\n",
      "                # and it's not on the lists of possible names/last names\n",
      "                if not (token in first_name or token in last_name):\n",
      "                    # consider it fake\n",
      "                    return False\n",
      "\n",
      "    return True"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": [
      "Test"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Run function in the test set, most of the names should be flagged as valid"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "not_true_name = []\n",
      "for name in testset:\n",
      "    if not is_real_name(name):\n",
      "        not_true_name.append(name)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Percentage rejected (false negative)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      " len(not_true_name)/len(testset)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "0.012276214833759591"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Some examples of obviously fake names"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "is_real_name('Some Random Words JR')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "is_real_name('Tancmln Ubncls')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 12
    }
   ],
   "metadata": {}
  }
 ]
}